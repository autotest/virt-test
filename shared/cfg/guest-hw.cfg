# Copy this file to guest-hw.cfg and edit it.
#
# NICs
variants:
    - rtl8139:
        no ppc64 ppc64le
        nic_model = rtl8139
    - e1000:
        no ppc64 ppc64le
        nic_model = e1000
    - e1000-82540em:
        no ppc64 ppc64le
        nic_model = e1000-82540em
    - e1000-82544gc:
        no ppc64 ppc64le
        nic_model = e1000-82544gc
    - e1000-82545em:
        no ppc64 ppc64le
        nic_model = e1000-82545em
    - virtio_net:
        nic_model = virtio
        # Assign the queue number of nic device
        #queues = 4
        # You can add advanced attributes on nic_extra_params such as mrg_rxbuf
        #nic_extra_params =
        # You can add advanced attributes through netdev_extra_params
        # such as sndbuf, as an example, you can uncomment the
        # following lines to enable the vhost support ( only available
        # for tap )
        #netdev_extra_params = ",vhost=on"
        enable_msix_vectors = yes
        whql.submission.device.net:
            test_device = VirtIO Ethernet Adapter$
            # Device selection for the NDISTest client machine
            dp_regex_testdev = VirtIO Ethernet Adapter$
            dp_regex_clientmsgdev = VirtIO Ethernet Adapter #2$
            dp_regex_clientsupportdev = VirtIO Ethernet Adapter #3$
            # Device selection for the NDISTest server machine
            dp_regex_servermsgdev = VirtIO Ethernet Adapter$
            dp_regex_serversupportdev = VirtIO Ethernet Adapter #2$
        arm64:
            # Currently arm only supports virtio-net-device
            nic_model = virtio-net-device
            # Currently arm does not support msix vectors
            enable_msix_vectors = no
    - xennet:
        # placeholder
    - spapr-vlan:
        nic_model = spapr-vlan
        only pseries
    - nic_custom:
        # If people want to specify something different.

variants:
    - up:
        no autotest.npb autotest.tsc
    - smp2:
        smp = 2
        used_cpus = 2
        stress_boot: used_cpus = 10
        timedrift.with_load: used_cpus = 100

variants:
    - ide:
        drive_format=ide
        cd_format=ide
    - scsi:
        drive_format=scsi
    - sd:
        drive_format=sd
    - virtio_blk:
        drive_format=virtio
        cd_format=ide
        q35:
            cd_format=ahci
        # Add -drive ...boot=yes unless qemu-kvm is 0.12.1.2 or newer
        # then kvm_vm will ignore this option.
        image_boot=yes
        arm64:
            # Direct usage of virtio-blk-device (using mmio transports) is used
            # on arm64.
            drive_format=virtio-blk-device
            image_boot=yes
            cd_format = scsi-cd
            scsi_hba = virtio-scsi-device
    - virtio_scsi:
        no WinXP
        # supported formats are: scsi-hd, scsi-cd, scsi-disk, scsi-block,
        # scsi-generic
        # Use drive_format_$DISKNAME = "scsi-generic" to force disk driver
        # for single disk.
        # NOTE:  scsi-block and scsi-generic are pass-through physical dev only
        drive_format=scsi-hd
        cd_format=scsi-cd
        scsi_hba=virtio-scsi-pci
        libvirt_controller=virtio-scsi
    - spapr_vscsi:
        drive_format=scsi-hd
        cd_format=scsi-cd
        scsi_hba=spapr-vscsi
        libvirt_controller=spapr-vscsi
        only pseries
    - lsi_scsi:
        no Host_RHEL
        drive_format=scsi-hd
        cd_format=scsi-cd
        scsi_hba=lsi53c895a
    - ahci:
        drive_format=ahci
        cd_format=ahci
    - usb2:
        drive_format=usb2
        cd_format=usb2
        usbs += " install_ehci"
        usb_type_install_ehci = ich9-usb-ehci1
    - xenblk:
        # placeholder

variants:
    - qcow2v3:
        image_format = qcow2
        image_extra_params = "compat=1.1"
        check_image = yes
    - qcow2:
        image_format = qcow2
        check_image = yes
    - vmdk:
        no ioquit
        image_format = vmdk
    - raw:
        no ioquit
        image_format = raw
    - raw_dd:
        no ioquit
        image_format = raw
        create_with_dd = yes
        dd_create_cmd = "dd if=/dev/zero of=%s bs=1M count=%s"
    - qed:
        no ioquit
        image_format = qed
        check_image = yes

variants:
    - @no_pci_assignable:
        pci_assignable = no
    - pf_assignable:
        pci_assignable = pf
        # device_name is optional. If device_name not set, it will try to get
        # first available pf. If device_name set, but the device is not
        # available, it will also try to get first available pf.
        device_name = eth1
        nettype = bridge
        pf_filter_re = "82576 Gigabit Network"
        mac_ip_filter = "inet (.\d+.\d+.\d+.\d+).*?ether (.\w+:\w+:\w+:\w+:\w+:\w+)"
        RHEL.6, RHEL.5:
            mac_ip_filter = "HWaddr (.\w+:\w+:\w+:\w+:\w+:\w+)\s+?inet addr:(.\d+\.\d+\.\d+\.\d+)"
        mac_changeable = "yes"
        unattended_install:
            mac_changeable = no
    - vf_assignable:
        pci_assignable = vf
        nettype = bridge
        # Driver (kernel module) that supports SR-IOV hardware.
        # As of today (30-11-2009), we have 2 drivers for this type of hardware:
        # Intel® 82576 Gigabit Ethernet Controller - igb
        # Neterion® X3100™ - vxge
        driver = igb
        # vf_filter_re: Regex used to filter vf from lspci.
        vf_filter_re = "Virtual Function"
        # pf_filter_re: Regex used to filter pf from lspci. It will be used
        # when device_name could not filter the pf.
        pf_filter_re = "82576 Gigabit Network"
        # Driver option to specify the maximum number of virtual functions
        # (on vxge the option is , for example, is max_config_dev)
        # the default below is for the igb driver
        driver_option = "max_vfs=7"
        mac_ip_filter = "inet (.\d+.\d+.\d+.\d+).*?ether (.\w+:\w+:\w+:\w+:\w+:\w+)"
        RHEL.6, RHEL.5:
            mac_ip_filter = "HWaddr (.\w+:\w+:\w+:\w+:\w+:\w+)\s+?inet addr:(.\d+\.\d+\.\d+\.\d+)"
        mac_changeable = "yes"
        unattended_install:
            mac_changeable = no
        sr-iov.sr_iov_negative.negative_max_vfs:
            driver_option = "max_vfs=-1"
        sr-iov.sr_iov_negative.more_than_max_vfs:
            driver_option = "max_vfs=8"

variants:
    - @smallpages:
    - hugepages:
        setup_hugepages = yes
        # In some special conditions, such as low mem PPC systems, you might
        # want to define how many large memory pages you want to set directly.
        # If you don't, virt-test will use an heuristic to calculate the number
        # (default). The heuristic can be found on virttest/test_setup.py
        #target_hugepages = 500

        # In some special conditions, such as low mem PPC systems, one might
        # want to set the overhead to 0, so leave this configurable. Keep in
        # mind that, if target_hugepages is set, this value will be ignored
        # since virt test won't try to calculate the required pages.
        hugepages_qemu_overhead = 128

        # Similarly, on low mem systems if you deallocate hugepages and try
        # to allocate them again it won't be possible to find contiguous pages,
        # so make it possible to turn it off by setting this to 'no'.
        hugepages_deallocate = yes

        # Some other params that one might find useful to configure
        extra_params += " -mem-path /mnt/kvm_hugepage"
        domain_xml_snippet = "<memoryBacking><hugepages/></memoryBacking>"

variants:
    - @no_9p_export:
    - 9p_export:
        # 9p_fs_driver support include local, handle, proxy
        9p_fs_driver = local
        9p_export_dir = /mnt/
        # 9p_security_model support include passthrough, mapped, none
        9p_security_model = passthrough
        9p_immediate_writeout = no
        9p_readonly = no
        # Only used in case of proxy fs driver
        #9p_socket_name = /tmp/virtfs-9p-socket
        #9p_proxy_binary = virtfs-proxy-helper

variants image_backend:
    - @filesystem:
    - gluster:
        storage_type = glusterfs
        enable_gluster = yes
        # please go through https://github.com/autotest/virt-test/wiki/Virt-test-support-for-GlusterFs for more details.
        #Set the brick of gluster server. If set, will try to set gluster
        gluster_brick = "images/gl_test"
        #Set the volume name of gluster.
        gluster_volume_name = "vol_test"
        #Remote server address. Please set it if you want use remote gluster server.
        #Please also unset gluster_brick.
        gluster_server = gluster-virt-qe-01.qe.lab.eng.nay.redhat.com

        unattended_install:
            enable_gluster_install = yes
            enable_gluster =  no
            enable_gluster_image1 = yes
    - lvm_partition:
        # use real logical volume partition as qemu block device drive
        only raw
        force_create_image = no
        image_raw_device = yes
        storage_type = lvm
        emulational_device = no
        # vg_name specify a exists real logical volume group name,
        # although we support setup a real lvm envrioment automatically,
        # but it's not ot recommended and it maybe destroy data on your
        # hard disk; If in demand, please configure your pv_name and
        # give a vg_name and lv_name;
        vg_name = autotest_vg
        #pv_name = /dev/sdb
        #lv_name = test_lv
        # command to reload lvm monitor serivce
        #lvm_reload_cmd = "systemctl reload lvm2-lvmetad.service;"
        #lvm_reload_cmd += "systemctl reload lvm2-monitor.service"
        force_remove_image = no
    - emulated_lvm:
        storage_type = emulated lvm
        only raw
        force_create_image = no
        image_raw_device = yes
        storage_type = lvm
        emulational_device = yes
        # specify a file as emulated volume, if not will create file in
        # autotest data dir;
        #emulated_image =
        force_remove_image = no
        remove_emulated_image = no
        #lvm_reload_cmd = "systemctl reload lvm2-lvmetad.service;"
        #lvm_reload_cmd += "systemctl reload lvm2-monitor.service"
    - ceph:
        storage_type = ceph
        # Some test case may need images from different backend. Please set up
        # enable_ceph_$image_name to no if the special image is not use ceph
        # server in your test
        enable_ceph = yes
        cmds_installed_host += " rbd"
        # Please update following parameters based on your test env
        #ceph_monitor = $ceph_monitor_ip
        #rbd_pool_name = $autotest_pool_name
    - emulational_iscsi:
        only raw
        storage_type = emulational_iscsi
        emulated_image = /tmp/iscsitest
        target = iqn.iscsi-emulation
        image_raw_device = yes
        storage_type = iscsi
        force_create_image = no
    - iscsi:
        # Please update portal_ip, target and initiator params based on your test env
        only raw
        storage_type = iscsi
        #portal_ip = 192.168.12.10
        #target = iqn.2001-05.com.equallogic:0-8a0906-db31f7d03-470263b05654c204-kvm-autotest
        #initiator = iqn.2010-07.com.redhat:kvmautotest
        image_raw_device = yes
        storage_type = iscsi
        force_create_image = no
    - remote_nfs:
        storage_type = nfs
        nfs_mount_dir = /mnt/nfs_images
        nfs_mount_options = rw
        # Please update nfs_mount_src base your nfs server
        #nfs_mount_src = 192.168.12.10:/vol/s2imagetest
    - local_nfs:
        storage_type = nfs
        nfs_mount_dir = /mnt/nfs_images
        nfs_mount_options = rw
        export_dir = /mnt/nfs_export
        nfs_mount_src = localhost:/mnt/nfs_export
        setup_local_nfs = yes
        export_options = rw

variants:
    - @no_virtio_rng:
    - rng_random:
        no Host_RHEL.5 Host_RHEL.6.0 Host_RHEL.6.1 Host_RHEL.6.2 Host_RHEL.3 Host_RHEL.6.4 Host_RHEL.6.5
        virtio_rngs += " rng0"
        #max-bytes_virtio-rng-pci =
        #period_virtio-rng-pci =
        backend_rng0 = rng-random
        backend_type = passthrough
        filename_passthrough = /dev/random
    - rng_egd:
        no Host_RHEL.5 Host_RHEL.6.0 Host_RHEL.6.1 Host_RHEL.6.2 Host_RHEL.3 Host_RHEL.6.4 Host_RHEL.6.5
        virtio_rngs += "rng0"
        #max-bytes_virtio-rng-pci =
        #period_virtio-rng-pci =
        backend_rng0 = rng-egd
        backend_type = chardev
        chardev_backend = socket
        socket_type = tcp
        host_tcp = localhost
        port_tcp = 8000
        # if egd.pl started on remote host, please set setup_egd = no
        setup_egd = yes

variants:
    - @default_bios:
    - ovmf:
        no i386 ppc64 ppc64le
        no Win2003 WinXP WinVista
        # Please update this based on your test env
        ovmf_path = /usr/share/OVMF
        ovmf_code_filename = OVMF_CODE.fd
        ovmf_vars_filename = OVMF_VARS.fd
        unattended_install:
            restore_ovmf_vars = yes
            Windows:
                use_ovmf_autounattend = yes
                send_key_at_install = ret

# Nettype
variants:
    - @bridge:
        nettype = bridge
    - macvtap:
        nettype = macvtap
    - user:
        nettype = user
    - network:
        nettype = network

